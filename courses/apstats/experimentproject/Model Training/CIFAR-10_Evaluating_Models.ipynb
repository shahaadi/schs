{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip uninstall tensorflow -y\n",
    "!pip install tensorflow==2.13.0"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 957
    },
    "id": "K35R69hPGyu_",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1699164755768,
     "user_tz": 420,
     "elapsed": 49243,
     "user": {
      "displayName": "Aadi Shah",
      "userId": "12796109776879309344"
     }
    },
    "outputId": "a0debf66-46dc-45ce-c204-86b2c55d2b0c"
   },
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found existing installation: tensorflow 2.13.0\n",
      "Uninstalling tensorflow-2.13.0:\n",
      "  Successfully uninstalled tensorflow-2.13.0\n",
      "Collecting tensorflow==2.13.0\n",
      "  Using cached tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.59.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.9.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.13.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (67.7.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.34.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.13.0) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.2.2)\n",
      "Installing collected packages: tensorflow\n",
      "Successfully installed tensorflow-2.13.0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "tensorflow"
        ]
       }
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1515,
     "status": "ok",
     "timestamp": 1699165965559,
     "user": {
      "displayName": "Aadi Shah",
      "userId": "12796109776879309344"
     },
     "user_tz": 420
    },
    "id": "HGbIUGmQ4N4X",
    "outputId": "5bdc730b-0cc5-443d-c966-d03413164a1f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.13.0\n",
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "\n",
    "# Display the version\n",
    "print(tf.__version__)\n",
    "\n",
    "# import and mount Drive\n",
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 147,
     "status": "ok",
     "timestamp": 1699164790526,
     "user": {
      "displayName": "Aadi Shah",
      "userId": "12796109776879309344"
     },
     "user_tz": 420
    },
    "id": "Fu573QMdfw91",
    "outputId": "d98ec2e5-4384-405b-fd2e-8159a417dbc2"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/gdrive/MyDrive/apstats-experimentproject\n"
     ]
    }
   ],
   "source": [
    "# get path to folder file is in\n",
    "file_path = '/content/gdrive/MyDrive/apstats-experimentproject'\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1505,
     "status": "ok",
     "timestamp": 1699164793486,
     "user": {
      "displayName": "Aadi Shah",
      "userId": "12796109776879309344"
     },
     "user_tz": 420
    },
    "id": "4ultGLyr5poj",
    "outputId": "d974aa71-d8a9-4853-a86b-6c6c12ea3774"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_train shape (50000, 32, 32, 3)\n",
      "y_train shape (50000, 1)\n",
      "X_test shape (10000, 32, 32, 3)\n",
      "y_test shape (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Download the data from tf, unless it's already here.\n",
    "if not os.path.exists(file_path+'/data/clean'):\n",
    "  os.mkdir(file_path+'/data/clean')\n",
    "  (X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "  np.save(file_path+'/data/clean/X_train.npy',X_train)\n",
    "  np.save(file_path+'/data/clean/y_train.npy',y_train)\n",
    "  np.save(file_path+'/data/clean/X_test.npy',X_test)\n",
    "  np.save(file_path+'/data/clean/y_test.npy',y_test)\n",
    "else:\n",
    "  X_train = np.load(file_path+'/data/clean/X_train.npy')\n",
    "  y_train = np.load(file_path+'/data/clean/y_train.npy')\n",
    "  X_test = np.load(file_path+'/data/clean/X_test.npy')\n",
    "  y_test = np.load(file_path+'/data/clean/y_test.npy')\n",
    "\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5fofaSwxaix7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1699164794588,
     "user_tz": 420,
     "elapsed": 967,
     "user": {
      "displayName": "Aadi Shah",
      "userId": "12796109776879309344"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Convert to float32\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Decrease pixel values\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6747,
     "status": "ok",
     "timestamp": 1699164802069,
     "user": {
      "displayName": "Aadi Shah",
      "userId": "12796109776879309344"
     },
     "user_tz": 420
    },
    "id": "4ZWzPmjC1qXw",
    "outputId": "f29d9c71-6363-46f3-ef18-e99ad4a01749"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_FGSM_train shape (50000, 32, 32, 3)\n",
      "y_train shape (50000, 1)\n",
      "X_FGSM_test shape (10000, 32, 32, 3)\n",
      "y_test shape (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Create FGSM Perturbed Data\n",
    "def create_fgsm_perturbations(data_inputs, data_labels, epsilon = 0.1):\n",
    "  input_tensor = tf.convert_to_tensor(data_inputs)\n",
    "  label_tensor = tf.convert_to_tensor(data_labels)\n",
    "  loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "  with tf.GradientTape() as tape:\n",
    "    tape.watch(input_tensor)\n",
    "    output_tensor = model(input_tensor)\n",
    "    loss = loss_fn(label_tensor, output_tensor)\n",
    "\n",
    "  gradient = tape.gradient(loss, input_tensor)\n",
    "  perturbed_input_tensor = input_tensor + epsilon * tf.sign(gradient)\n",
    "  return tf.cast(perturbed_input_tensor, dtype=input_tensor.dtype)\n",
    "\n",
    "# Create FGSM perturbations if nonexisting, else load them\n",
    "if not os.path.exists(file_path+'/data/FGSM_perturbed'):\n",
    "  os.mkdir(file_path+'/data/FGSM_perturbed')\n",
    "\n",
    "  perturbed_data = [None for _ in range(5)]\n",
    "  for i in range(5):\n",
    "    perturbed_data[i] = create_fgsm_perturbations(X_train[i * 10000:(i+1) * 10000], y_train[i * 10000:(i+1) * 10000])\n",
    "\n",
    "  X_FGSM_train = np.concatenate(perturbed_data, axis=0)\n",
    "  X_FGSM_test = create_fgsm_perturbations(X_test, y_test)\n",
    "\n",
    "  np.save(file_path+'/data/FGSM_perturbed/X_FGSM_train.npy',X_FGSM_train)\n",
    "  np.save(file_path+'/data/FGSM_perturbed/X_FGSM_test.npy',X_FGSM_test)\n",
    "else:\n",
    "  X_FGSM_train = np.load(file_path+'/data/FGSM_perturbed/X_FGSM_train.npy')\n",
    "  X_FGSM_test = np.load(file_path+'/data/FGSM_perturbed/X_FGSM_test.npy')\n",
    "\n",
    "print(\"X_FGSM_train shape\", X_FGSM_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"X_FGSM_test shape\", X_FGSM_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2ssrncZ5fMUE",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1699164803963,
     "user_tz": 420,
     "elapsed": 1899,
     "user": {
      "displayName": "Aadi Shah",
      "userId": "12796109776879309344"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Clip perturbed training and test data to viable values\n",
    "X_FGSM_train = np.clip(X_FGSM_train, a_min = 0.0, a_max = 1.0)\n",
    "X_FGSM_test = np.clip(X_FGSM_test, a_min = 0.0, a_max = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5610,
     "status": "ok",
     "timestamp": 1699164809571,
     "user": {
      "displayName": "Aadi Shah",
      "userId": "12796109776879309344"
     },
     "user_tz": 420
    },
    "id": "-Tb7Cy5xsbsP",
    "outputId": "6dfa9be9-50c0-4f03-f002-106fa66bc9e9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_PGD_train shape (50000, 32, 32, 3)\n",
      "y_train shape (50000, 1)\n",
      "X_PGD_test shape (10000, 32, 32, 3)\n",
      "y_test shape (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Create PGD Perturbed Data\n",
    "def create_pgd_perturbations(data_inputs, data_labels, epsilon = 0.01, n_iter = 10):\n",
    "  input_tensor = tf.convert_to_tensor(data_inputs)\n",
    "  label_tensor = tf.convert_to_tensor(data_labels)\n",
    "  loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "  perturbed_tensor = input_tensor\n",
    "  for i in range(n_iter):\n",
    "      with tf.GradientTape() as tape:\n",
    "          tape.watch(perturbed_tensor)\n",
    "          output_tensor = model(perturbed_tensor)\n",
    "          loss = loss_fn(label_tensor, output_tensor)\n",
    "\n",
    "      gradient = tape.gradient(loss, perturbed_tensor)\n",
    "\n",
    "      perturbed_tensor = perturbed_tensor + gradient\n",
    "      # Project perturbed_tensor onto the L-infinity ball around input_tensor\n",
    "      perturbed_tensor = epsilon * tf.sign(\n",
    "          perturbed_tensor - input_tensor) + input_tensor\n",
    "\n",
    "  perturbed_tensor = tf.cast(perturbed_tensor, dtype=input_tensor.dtype)\n",
    "  return perturbed_tensor\n",
    "\n",
    "# Create PGD perturbations if nonexisting, else load them\n",
    "if not os.path.exists(file_path+'/data/PGD_perturbed'):\n",
    "  os.mkdir(file_path+'/data/PGD_perturbed')\n",
    "\n",
    "  perturbed_data = [None for _ in range(5)]\n",
    "  for i in range(5):\n",
    "    perturbed_data[i] = create_fgsm_perturbations(X_train[i * 10000:(i+1) * 10000], y_train[i * 10000:(i+1) * 10000])\n",
    "\n",
    "  X_PGD_train = np.concatenate(perturbed_data, axis=0)\n",
    "  X_PGD_test = create_pgd_perturbations(X_test, y_test)\n",
    "\n",
    "  np.save(file_path+'/data/PGD_perturbed/X_PGD_train.npy',X_PGD_train)\n",
    "  np.save(file_path+'/data/PGD_perturbed/X_PGD_test.npy',X_PGD_test)\n",
    "else:\n",
    "  X_PGD_train = np.load(file_path+'/data/PGD_perturbed/X_PGD_train.npy')\n",
    "  X_PGD_test = np.load(file_path+'/data/PGD_perturbed/X_PGD_test.npy')\n",
    "\n",
    "print(\"X_PGD_train shape\", X_PGD_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"X_PGD_test shape\", X_PGD_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Q7ig4Xa_n-Bp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1699164810443,
     "user_tz": 420,
     "elapsed": 884,
     "user": {
      "displayName": "Aadi Shah",
      "userId": "12796109776879309344"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Clip perturbed training and test data to viable values\n",
    "X_PGD_train = np.clip(X_PGD_train, a_min = 0.0, a_max = 1.0)\n",
    "X_PGD_test = np.clip(X_PGD_test, a_min = 0.0, a_max = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def createDataSplit(x, y):\n",
    "  x_first, x_second, y_first, y_second = train_test_split(x, y, test_size=0.5, stratify=y)\n",
    "  X_clean_model_test, X_FGSM_model_test, y_clean_model_test, y_FGSM_model_test = train_test_split(x_first, y_first, test_size=0.5, stratify=y_first)\n",
    "  X_PGD_model_test, X_DD_model_test, y_PGD_model_test, y_DD_model_test = train_test_split(x_second, y_second, test_size=0.5, stratify=y_second)\n",
    "  return X_clean_model_test, y_clean_model_test, X_FGSM_model_test, y_FGSM_model_test, X_PGD_model_test, y_PGD_model_test, X_DD_model_test, y_DD_model_test"
   ],
   "metadata": {
    "id": "A6SxgdIkrpcs",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1699164811234,
     "user_tz": 420,
     "elapsed": 793,
     "user": {
      "displayName": "Aadi Shah",
      "userId": "12796109776879309344"
     }
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X_clean_model_test, y_clean_model_test, X_FGSM_model_test, y_FGSM_model_test, X_PGD_model_test, y_PGD_model_test, X_DD_model_test, y_DD_model_test = createDataSplit(X_PGD_test, y_test)"
   ],
   "metadata": {
    "id": "65aIwhF0xol7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1699164811403,
     "user_tz": 420,
     "elapsed": 171,
     "user": {
      "displayName": "Aadi Shah",
      "userId": "12796109776879309344"
     }
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load in Clean Model\n",
    "print(\"clean model:\\n\")\n",
    "model = tf.keras.models.load_model(file_path+'/models/clean.keras')\n",
    "clean_model_prob = pd.DataFrame(model.predict(X_clean_model_test)[np.arange(2500), y_clean_model_test[:, 0]])\n",
    "clean_model_prob.to_csv(file_path+'/output_data/clean_model_prob.csv')\n",
    "\n",
    "# Load in FGSM Model\n",
    "print(\"\\nfgsm model:\\n\")\n",
    "fgsm_model = tf.keras.models.load_model(file_path+'/models/mixed_FGSM.keras')\n",
    "fgsm_model_prob = pd.DataFrame(fgsm_model.predict(X_FGSM_model_test)[np.arange(2500), y_FGSM_model_test[:, 0]])\n",
    "fgsm_model_prob.to_csv(file_path+'/output_data/fgsm_model_prob.csv')\n",
    "\n",
    "# Load in PGD Model\n",
    "print(\"\\npgd model:\\n\")\n",
    "pgd_model = tf.keras.models.load_model(file_path+'/models/mixed_PGD.keras')\n",
    "pgd_model_prob = pd.DataFrame(pgd_model.predict(X_PGD_model_test)[np.arange(2500), y_PGD_model_test[:, 0]])\n",
    "pgd_model_prob.to_csv(file_path+'/output_data/pgd_model_prob.csv')\n",
    "\n",
    "def temperature_cross_entropy(gt, pred):\n",
    "  loss = tf.nn.softmax_cross_entropy_with_logits(labels=gt, logits=pred/20)\n",
    "  return loss\n",
    "\n",
    "# Load in Distilled Model\n",
    "print(\"\\ndistilled model:\\n\")\n",
    "distilled_model = tf.keras.models.load_model(file_path+'/models/distillation_student.keras', custom_objects={'temperature_cross_entropy': temperature_cross_entropy})\n",
    "dd_model_prob = pd.DataFrame(tf.nn.softmax(distilled_model.predict(X_DD_model_test)).numpy()[np.arange(2500), y_DD_model_test[:, 0]])\n",
    "dd_model_prob.to_csv(file_path+'/output_data/dd_model_prob.csv')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hHkDtOHi4AhV",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1699166012361,
     "user_tz": 420,
     "elapsed": 17261,
     "user": {
      "displayName": "Aadi Shah",
      "userId": "12796109776879309344"
     }
    },
    "outputId": "7c4d591d-6b6f-4550-8290-fbe2320cf9e2"
   },
   "execution_count": 48,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "clean model:\n",
      "\n",
      "79/79 [==============================] - 3s 42ms/step\n",
      "\n",
      "fgsm model:\n",
      "\n",
      "79/79 [==============================] - 5s 55ms/step\n",
      "\n",
      "pgd model:\n",
      "\n",
      "79/79 [==============================] - 3s 31ms/step\n",
      "\n",
      "distilled model:\n",
      "\n",
      "79/79 [==============================] - 3s 31ms/step\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

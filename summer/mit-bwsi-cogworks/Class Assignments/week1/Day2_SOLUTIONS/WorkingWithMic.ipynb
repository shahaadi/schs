{
 "cells": [
  {
   "cell_type": "raw",
   "id": "241f1e88",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. meta::\n",
    "    :description: Topic: recording sound, Category: Exercises\n",
    "    :keywords: analog, digital, microphone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3156d06c",
   "metadata": {},
   "source": [
    "# Exercises: Working with the Microphone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750cc678",
   "metadata": {},
   "source": [
    "In this notebook, we will learn how to access the digitized audio recording our microphones, and access the audio samples as a numpy array of data that we can analyze and manipulate.\n",
    "We will write functions for writing and reading our own numpy-based audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "825a184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from typing import Tuple\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05267a7",
   "metadata": {},
   "source": [
    "As discussed in the [preceding section](https://rsokl.github.io/CogWeb/Audio/digitizing_signals.html), a microphone is responsible for converting the information carried by sound waves into an analog electrical signal, which it then digitizes through a process comparable to pulse code modulation (PCM). \n",
    "Let's take some time to understand how we can access the digital audio samples that are recorded by your microphone. \n",
    "\n",
    "Your microphone stores the audio on buffer frames, which is just an area of RAM made for temporary storage.\n",
    "Buffers are typically used when there is a difference between the rate at which data is received and the rate at which it can be processed.\n",
    "The details of buffer frames are not especially important though.\n",
    "We only need to know that our digital signal will be stored as a collection of bytes in memory across a number of frames.\n",
    "\n",
    "## Using the Microphone Python Package\n",
    "The `microphone.record_audio` package records and digitizes an analog signal and returns a tuple containing \n",
    "\n",
    "1. a list of bytes in memory corresponding to the digital signal \n",
    "2. the sampling rate.\n",
    "\n",
    "(Remember that, in a Jupyter Notebook, you can check this by inspecting the function's docstring with `SHIFT-TAB`)\n",
    "\n",
    "For example, consider the following code\n",
    "\n",
    "```python\n",
    "from microphone import record_audio\n",
    "listen_time = 5  # seconds\n",
    "frames, sample_rate = record_audio(listen_time)\n",
    "```\n",
    "\n",
    "Here `sample_rate` is the sampling rate, $f_s$, used by the microphone to record the digital signal.\n",
    "Since all we need to know in order to reconstruct the original signal from bytes in memory are the sampling rate and the number of samples, it is extremely important that we keep track of `sample_rate`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084893f0",
   "metadata": {},
   "source": [
    "(1.2.1) Use the `record_audio` function to record and digitize an analog signal that lasts five seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa52c1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using input device 'MacBook Pro Microphone'\n",
      "Recording ended\n"
     ]
    }
   ],
   "source": [
    "from microphone import record_audio\n",
    "\n",
    "listen_time = 5  # <COGSTUB> seconds\n",
    "frames, sample_rate = record_audio(listen_time)  # <COGSTUB> record audio for the listen time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6667eedb",
   "metadata": {},
   "source": [
    "The `frames` variable is a list of bytes in memory that compose the entirety of the recorded digital signal.\n",
    "To anyone except a computer, the elements of `frames` are indecipherable;\n",
    "just try inspecting the first 15 elements of `frames[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a9c2de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample-rate: 44100\n",
      "num frames: 215\n",
      "num bytes per frame: 2048\n",
      "first 15 bytes frame: b'\\t\\x00\\x14\\x00\\x1a\\x00\\x1a\\x00\\x1b\\x00\\x1b\\x00\\x1a\\x00\\x1b'\n"
     ]
    }
   ],
   "source": [
    "# print:\n",
    "# - sample_rate\n",
    "# - len(frames)  <- the number of frames\n",
    "# - len(frames[0])  <- the number of bytes in frame 0\n",
    "# - frames[0][:15]  <- the first 15 bytes in frame 0\n",
    "\n",
    "# <COGINST>\n",
    "print(f\"sample-rate: {sample_rate}\")\n",
    "print(f\"num frames: {len(frames)}\")\n",
    "print(f\"num bytes per frame: {len(frames[0])}\")\n",
    "print(f\"first 15 bytes frame: {frames[0][:15]}\")\n",
    "# </COGINST>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d43f0e",
   "metadata": {},
   "source": [
    "To make the data useful to us, we will need to convert each of the bytes into $16$-bit integers, under the assumption that the microphone used the standard bit depth of $N_b=16$.\n",
    "To do so, we can use the [numpy.frombuffer](https://numpy.org/doc/1.18/reference/generated/numpy.frombuffer.html) function. In particular,\n",
    "\n",
    "```python\n",
    "np.frombuffer(frames[0], np.int16)\n",
    "```\n",
    "\n",
    "will read in the first frame and return a 1-D NumPy array containing $16$-bit integers.\n",
    "In order to convert the entire digital signal into readable integers, we will need to iterate over each frame in `frames` and use `np.frombuffer(..., np.int16)` to convert each \"frame\" of bytes into an array of 16-bit integers.\n",
    "We can then use the [numpy.hstack](https://numpy.org/doc/1.18/reference/generated/numpy.hstack.html) function to join all of these arrays together into a single array of all of 16-bit integers that make up the digital audio recording:\n",
    "\n",
    "```python\n",
    "# Converting bytes of memory that was written to by our microphone\n",
    "# into a single array of 16-bit integers.\n",
    "# This array stores the digital audio data of our recording\n",
    "samples = np.hstack([np.frombuffer(i, np.int16) for i in frames])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56da119b",
   "metadata": {},
   "source": [
    "(1.2.1 cont'd) Following the above code block, iterate through each frame and convert the bytes into NumPy arrays of $16$-bit integers.\n",
    "Finally, concatenate all the NumPy arrays in order to have a single array corresponding to the full digital signal.\n",
    "[List comprehensions](https://www.pythonlikeyoumeanit.com/Module2_EssentialsOfPython/Generators_and_Comprehensions.html#List-&-Tuple-Comprehensions) using [numpy.hstack](https://numpy.org/doc/1.18/reference/generated/numpy.hstack.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b432b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.hstack([np.frombuffer(i, np.int16) for i in frames])  # <COGSTUB>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64f47c7",
   "metadata": {},
   "source": [
    "You can listen to the audio samples are stored in the resulting NumPy array (_not_ the memory frames) using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6436edef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listen to your recording \n",
    "Audio(samples, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee82c40",
   "metadata": {},
   "source": [
    "Now that we have made our digital signal a bit more useful, let's save our digital signal so we can work with it even when we need to restart our Jupyter Notebook kernel.\n",
    "Thankfully NumPy provides us with the capability to save arrays to disk (as `npy` files) with the [numpy.save](https://numpy.org/doc/1.18/reference/generated/numpy.save.html) function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5699bc5a",
   "metadata": {},
   "source": [
    "## Writing Our Own Audio Files (Using NumPy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f47171",
   "metadata": {},
   "source": [
    "(1.2.2) Write a function that records an analog signal and [writes the resulting digital signal to a](https://www.pythonlikeyoumeanit.com/Module5_OddsAndEnds/WorkingWithFiles.html#Saving-and-Loading-NumPy-Arrays) `npy` file.\n",
    "Remember that we will also want to save the sampling rate of the digital signal, so make the array you save have as its first element the sampling rate.\n",
    "In other words, `array_to_save[0] == sample_rate` and `array_to_save[1:] == samples[:]`.\n",
    "This additional information that we save are saving to the beginning of our array, to provide context for interpreting the rest of the data in the array, is often referred to as a \"file header\".\n",
    "\n",
    "An important note: we converted the bytes in the buffer frames into signed $16$-bit integers. However, the standard sampling rate of $44,100\\:\\mathrm{Hz}$ cannot be stored as a signed $16$-bit integer (the largest signed 16-bit integer is $\\pm 32,768$), meaning that in order to store `sample_rate` alongside `samples`, `array_to_save` must store $32$-bit integers instead of $16$-bit integers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db55924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_and_save(listen_time: float, file_path: str):\n",
    "    \"\"\"\n",
    "    Uses microphone to record and digitize an analog signal \n",
    "    and save the resulting digital signal and sampling rate to npy file.\n",
    "    \n",
    "    The first element in the saved array should store the the sample-rate;\n",
    "    the remaining elements in the array should store the sampled data itself.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    listen_time : float\n",
    "        Length of recording in seconds.\n",
    "        \n",
    "    file_path : Union[str, pathlib.Path]\n",
    "        Path to the file destination. E.g. \"my_audio.npy\" will save an audio\n",
    "        file called \"my_audio.npy\" to the current working directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Record audio for appropriate amount of time, producing frames & sample-rate\n",
    "    # 2. Convert frames to array of 16-bit integers (samples)\n",
    "    # 3. Create a 32-bit int array whose first element is the sample-rate \n",
    "    #   (this is the \"header\" of our audio file)\n",
    "    #    and the rest of the elements are the samples (stored as 32-bit ints)\n",
    "    # 4. Save this array to the specified file-path\n",
    "    \n",
    "    # <COGINST>\n",
    "    frames, sample_rate = record_audio(listen_time)\n",
    "\n",
    "    samples = np.hstack([np.frombuffer(i, np.int16) for i in frames])\n",
    "    array_to_save = np.hstack((sample_rate, samples))\n",
    "\n",
    "    np.save(file_path, array_to_save)\n",
    "    # </COGINST>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebec585",
   "metadata": {},
   "source": [
    "(1.2.3) Now that we've devised a way to record and save a digital signal to a file, we need a way to load that file.\n",
    "Write a function that loads a digital signal saved by your previous function. It should return a tuple containing\n",
    "\n",
    "1. the NumPy array that stores the samples of our recording.\n",
    "2. the sampling rate of the recording.\n",
    "\n",
    "The function [numpy.load](https://numpy.org/doc/1.18/reference/generated/numpy.load.html) will be handy here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42736881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_parse(file_path: str) -> Tuple[np.ndarray, int]:\n",
    "    \"\"\"\n",
    "    Loads a saved digital signal from an npy file and returns the signal and the sampling rate.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : Union[str, pathlib.Path]\n",
    "        Path to the numpy-based audio file (.npy) to be loaded\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[np.ndarray, int]\n",
    "        A tuple containing two elements:\n",
    "        - element 0: The digital signal as a NumPy array (shape-(N,) array)\n",
    "        - element 1: The sampling rate (int)\n",
    "    \"\"\"\n",
    "    # <COGINST>\n",
    "    loaded_array = np.load(file_path)\n",
    "    \n",
    "    sample_rate = loaded_array[0]\n",
    "    signal = loaded_array[1:]\n",
    "    \n",
    "    return signal, sample_rate\n",
    "    # </COGINST>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c1ad52",
   "metadata": {},
   "source": [
    "Use these functions to record a $2$ second recording and save a digital audio file.\n",
    "Then load the signal and sample rate from the audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb135f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a 2 second recording to \"digital_signal.npy\"  \n",
    "record_and_save(listen_time=2, file_path=\"digital_signal.npy\")  # <COGLINE>\n",
    "\n",
    "samples, sample_rate = load_and_parse(file_path=\"digital_signal.npy\")  # <COGSTUB> load the digital_signal.npy recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ecf016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print:\n",
    "# - sample_rate\n",
    "# - len(samples)  <- the number of samples\n",
    "# - samples[:15]  <- the first 15 samples (a lot of these might be 0)\n",
    "\n",
    "# <COGINST>\n",
    "print(f\"sample-rate: {sample_rate}\")\n",
    "print(f\"num samples: {len(samples)}\")\n",
    "print(f\"first 15 samples: {samples[:15]}\")\n",
    "# </COGINST>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b2dd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listen to your recording using the Audio(samples, rate=sampling_rate)\n",
    "\n",
    "Audio(samples, rate=sample_rate) # <COGLINE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e366e2ae",
   "metadata": {},
   "source": [
    "## Visualizing an Audio Recording"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6367edb1",
   "metadata": {},
   "source": [
    "(1.2.4) Now that we can read the digital signal back into Python, let's determine the times at which the analog signal was sampled.\n",
    "Remember, we only need to know two things to do this, the number of samples ($N$) and the sampling rate ($f_s$).\n",
    "\n",
    "Define the variable `times` – a NumPy array containing the times at which the analog signal was sampled.\n",
    "The size of `times` should be the same as the size of the array containing our audio samples (`samples`), and the final value in `times` (i.e. `times[-1]`) should be very close the initial recording length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eccaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.arange(samples.size) / sample_rate # <COGSTUB> compute based off of `samples` and `sample_rate`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b992c998",
   "metadata": {},
   "source": [
    "(1.2.5) Finally, let's plot our digital signal.\n",
    "First, plot the digital signal recorded by the computer.\n",
    "\n",
    "```python\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(your_x_values, your_y_values)\n",
    "ax.set_xlabel(\"Your x label\")\n",
    "ax.set_ylabel(\"Your y label\")\n",
    "ax.set_title(\"Your title\")\n",
    "```\n",
    "\n",
    "Label your axes and include units. The values that you recorded in your microphone aren't direct voltage measurements, but they are proportional to it – suffice it to label the $y$-axis as `\"Proportional to Volts\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adab00b2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# <COGINST>\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(times, samples)\n",
    "ax.set_title(\"44,100 Hz Sampling Rate\")\n",
    "ax.set_xlabel(\"Time [seconds]\")\n",
    "ax.set_ylabel(\"Proportional to Volts\")\n",
    "ax.grid(True)\n",
    "# </COGINST>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29fc5ad",
   "metadata": {},
   "source": [
    "Then, plot every $441^\\text{th}$ time and sample of the digital signal;\n",
    "assuming the original sampling rate is the standard $f_s=44,100 \\:\\mathrm{Hz}$, this re-sampled signal would correspond to the case where we had used a sampling rate of only $f_s=100\\:\\mathrm{Hz}$.\n",
    "\n",
    "Think about how we can create this low-rate, re-sampled signal by simply [slicing](https://www.pythonlikeyoumeanit.com/Module2_EssentialsOfPython/SequenceTypes.html#Slicing) into our original arrays of times and samples.\n",
    "\n",
    "Label your axes and include units. The values that you recorded in your microphone aren't direct voltage measurements, but they are proportional to it – suffice it to label the $y$-axis as `\"Proportional to Volts\"`\n",
    "\n",
    "Your x-axis (time) for this re-sampled figure should show the same overall duration as the original plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280736d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <COGINST>\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "low_sampled_times = times[::441]\n",
    "low_sampled_samples = samples[::441]\n",
    "\n",
    "ax.plot(low_sampled_times, low_sampled_samples)\n",
    "ax.set_title(\"100 Hz Sampling Rate\")\n",
    "ax.set_xlabel(\"Time [seconds]\")\n",
    "ax.set_ylabel(\"Proportional to Volts\")\n",
    "ax.grid(True)\n",
    "# </COGINST>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dedcaf",
   "metadata": {},
   "source": [
    "Try making new recordings (perhaps for longer durations). Try whistling, clapping, etc. Plot these digital signals and see if you can visually match the signals that you see with the audio that you recorded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df01ecc0",
   "metadata": {},
   "source": [
    "Congratulations! You created your own custom audio format, complete with functionality for saving and loading audio files!"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python",
   "notebook_metadata_filter": "nbsphinx,-kernelspec"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "nbsphinx": {
   "execute": "never"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "raw",
   "id": "edf73c06",
   "metadata": {},
   "source": [
    ".. meta::\n",
    "    :description: Topic: matching audio, Category: Exercises\n",
    "    :keywords: fingerprint, audio matching, local maxima"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103745cc",
   "metadata": {},
   "source": [
    "# Exercises: Finding Local Peaks in a 2-D Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31155e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "\n",
    "from scipy.ndimage.filters import maximum_filter\n",
    "from scipy.ndimage.morphology import generate_binary_structure\n",
    "from scipy.ndimage.morphology import iterate_structure\n",
    "\n",
    "from typing import Tuple, Callable, List\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b36045",
   "metadata": {},
   "source": [
    "## Toy Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefbae53",
   "metadata": {},
   "source": [
    "We want to find the primary points of contact made by puppy-paws on a pressure-sensor.\n",
    "There are $4$ images that are each $11\\times14$ pixels. \n",
    "Let's load and visualize this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4639372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads four images of puppy paw print pressure data\n",
    "paws = np.loadtxt(\"data/paws.txt\").reshape(4, 11, 14)\n",
    "print(paws.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3765c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots the paw prints\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2)\n",
    "for n, (i, j) in enumerate([(0, 0), (0, 1), (1, 0), (1, 1)]):\n",
    "    ax[i, j].imshow(paws[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d075ec4",
   "metadata": {},
   "source": [
    "For each \"toe\", we want to find the pixel with the maximum pressure.\n",
    "This corresponds to a finding the local peaks in a 2-D image.\n",
    "This is much more nuanced than finding the global maximum.\n",
    "The term \"local peak\" is also not completely well defined - we need to specify what we mean by \"local\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6394e68",
   "metadata": {},
   "source": [
    "### Defining a 2D neighborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcf9069",
   "metadata": {},
   "source": [
    "In order to find local peaks in our 2D data, we must first define what we mean by \"local\". We will use `scipy.ndimage.morphology.generate_binary_structure` and `from scipy.ndimage.morphology.iterate_structure` to generate a 2D boolean-valued array that represents our neighborhood.\n",
    "\n",
    "`generate_binary_structure` produces the a simple 2-D array of boolean values that indicate where we want to look within the neighborhood (i.e. `True` marks the elements that are included in the neighborhood).\n",
    "\n",
    "Let's generate and visualize this specific neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356fa514",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_binary_structure(rank=2, connectivity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75629d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(generate_binary_structure(rank=2, connectivity=1))\n",
    "ax.set_title(\"Rank-2, Connectivity-1\\nNeighborhood\")\n",
    "ax.get_xaxis().set_ticks([])\n",
    "ax.get_yaxis().set_ticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c794a9",
   "metadata": {},
   "source": [
    "What if we want to use a larger neighborhood? We can make use of `scipy.ndimage.morphology.iterate_structure` to \"grow\" the pattern created by `generate_binary_structure(2, 1)`.\n",
    "This allows us to set roughly the number of nearest neighbors (along a given direction) that that we want to included in the neighborhood.\n",
    "\n",
    "For instance, let's use `iterate_structure` to generate a neighborhood that includes two \"neighbors\" to each cardinal side (i.e. above/below and to the left/right) of the center element of the neighborhood:\n",
    "\n",
    "```python\n",
    ">>> base_structure = generate_binary_structure(2,1)\n",
    ">>> neighborhood = iterate_structure(base_structure, 2)\n",
    ">>> neighborhood\n",
    "array([[False, False,  True, False, False],\n",
    "       [False,  True,  True,  True, False],\n",
    "       [ True,  True,  True,  True,  True],\n",
    "       [False,  True,  True,  True, False],\n",
    "       [False, False,  True, False, False]], dtype=bool)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1170d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "base_structure = generate_binary_structure(2,1)\n",
    "neighborhood = iterate_structure(base_structure, 2)\n",
    "\n",
    "ax.imshow(neighborhood)\n",
    "ax.set_title(\"Iterated Neighborhood (nearest neighbor=2)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741ecf46",
   "metadata": {},
   "source": [
    "(1.8.1) Use `iterate_structure` to create a neighborhood the includes three \"neighbors\" to each side (left, right, top, and bottom respectively) of the center element.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c572766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <COGINST>\n",
    "base_structure = generate_binary_structure(2,1)\n",
    "neighborhood = iterate_structure(base_structure, 3)\n",
    "print(neighborhood)\n",
    "# </COGINST>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c6c835",
   "metadata": {},
   "source": [
    "In general, we will always generate a neighborhood array that has an odd number of rows and columns, respectively.\n",
    "This will ensure that our neighborhood has an unambiguous center element. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b2c7f5",
   "metadata": {},
   "source": [
    "### Finding the Actual Peaks\n",
    "\n",
    "The following code slides this \"local neighborhood mask\" over our grid of 2D data (e.g. our spectrogram of amplitudes).\n",
    "For whichever element the neighborhood is centered on, we see if:\n",
    "\n",
    "- That center element is larger than some minimum threshold, which must be exceeded as a requirement to be considered \"a peak\"\n",
    "- No neighbor (as defined by the neighborhood) is larger than that center element\n",
    "\n",
    "If these conditions are true, then that center element is considered to be a local peak.\n",
    "We then iterate to the next element in the 2D array and repeat the process; ultimately we will have iterated over the entire 2D array of data to so identify all of the local peaks.\n",
    "Note that this is a relatively simple way of doing local peak-finding, and is certainly not the most optimal algorithm to do so.\n",
    "\n",
    "Doing for-loops over large numpy arrays is typically something that we avoid doing due to considerations of speed.\n",
    "But we do not have access to a vectorized peak-finding algorithm, so for-loops are what we have to stick with.\n",
    "Fortunately, we can leverage a package called Numba to help speed up this code.\n",
    "Numba provides a \"just in time\" (JIT) compiler that is able to translate (some aspects of) Python code into optimized machine code.\n",
    "That is, whereas we have typically avoided writing for-loops over large arrays of data in Python in favor of vectorization, Numba enables us to write plain Python code using for-loops, but obtain a function that will run quickly, as if it had been implemented in a fast, compiled language like C.\n",
    "\n",
    "Study the following code to understand what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c915256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "\n",
    "# `@njit` \"decorates\" the `_peaks` function. This tells Numba to\n",
    "# compile this function using the \"low level virtual machine\" (LLVM)\n",
    "# compiler. The resulting object is a Python function that, when called,\n",
    "# executes optimized machine code instead of the Python code\n",
    "# \n",
    "# The code used in _peaks adheres strictly to the subset of Python and\n",
    "# NumPy that is supported by Numba's jit. This is a requirement in order\n",
    "# for Numba to know how to compile this function to more efficient\n",
    "# instructions for the machine to execute\n",
    "@njit\n",
    "def _peaks(\n",
    "    data_2d: np.ndarray, nbrhd_row_offsets: np.ndarray, nbrhd_col_offsets: np.ndarray, amp_min: float\n",
    ") -> List[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    A Numba-optimized 2-D peak-finding algorithm.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_2d : numpy.ndarray, shape-(H, W)\n",
    "        The 2D array of data in which local peaks will be detected.\n",
    "\n",
    "    nbrhd_row_offsets : numpy.ndarray, shape-(N,)\n",
    "        The row-index offsets used to traverse the local neighborhood.\n",
    "        \n",
    "        E.g., given the row/col-offsets (dr, dc), the element at \n",
    "        index (r+dr, c+dc) will reside in the neighborhood centered at (r, c).\n",
    "    \n",
    "    nbrhd_col_offsets : numpy.ndarray, shape-(N,)\n",
    "        The col-index offsets used to traverse the local neighborhood. See\n",
    "        `nbrhd_row_offsets` for more details.\n",
    "        \n",
    "    amp_min : float\n",
    "        All amplitudes equal to or below this value are excluded from being\n",
    "        local peaks.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    List[Tuple[int, int]]\n",
    "        (row, col) index pair for each local peak location, returned in \n",
    "        column-major order\n",
    "    \"\"\"\n",
    "    peaks = []  # stores the (row, col) locations of all the local peaks\n",
    "\n",
    "    # Iterating over each element in the the 2-D data \n",
    "    # in column-major ordering\n",
    "    #\n",
    "    # We want to see if there is a local peak located at\n",
    "    # row=r, col=c\n",
    "    for c, r in np.ndindex(*data_2d.shape[::-1]):\n",
    "        if data_2d[r, c] <= amp_min:\n",
    "            # The amplitude falls beneath the minimum threshold\n",
    "            # thus this can't be a peak.\n",
    "            continue\n",
    "        \n",
    "        # Iterating over the neighborhood centered on (r, c) to see\n",
    "        # if (r, c) is associated with the largest value in that\n",
    "        # neighborhood.\n",
    "        #\n",
    "        # dr: offset from r to visit neighbor\n",
    "        # dc: offset from c to visit neighbor\n",
    "        for dr, dc in zip(nbrhd_row_offsets, nbrhd_col_offsets):\n",
    "            if dr == 0 and dc == 0:\n",
    "                # This would compare (r, c) with itself.. skip!\n",
    "                continue\n",
    "\n",
    "            if not (0 <= r + dr < data_2d.shape[0]):\n",
    "                # neighbor falls outside of boundary.. skip!\n",
    "                continue\n",
    "\n",
    "            if not (0 <= c + dc < data_2d.shape[1]):\n",
    "                # neighbor falls outside of boundary.. skip!\n",
    "                continue\n",
    "\n",
    "            if data_2d[r, c] < data_2d[r + dr, c + dc]:\n",
    "                # One of the amplitudes within the neighborhood\n",
    "                # is larger, thus data_2d[r, c] cannot be a peak\n",
    "                break\n",
    "        else:\n",
    "            # if we did not break from the for-loop then (r, c) is a local peak\n",
    "            peaks.append((r, c))\n",
    "    return peaks\n",
    "\n",
    "# `local_peak_locations` is responsible for taking in the boolean mask `neighborhood`\n",
    "# and converting it to a form that can be used by `_peaks`. This \"outer\" code is \n",
    "# not compatible with Numba which is why we end up using two functions:\n",
    "# `local_peak_locations` does some initial pre-processing that is not compatible with\n",
    "# Numba, and then it calls `_peaks` which contains all of the jit-compatible code\n",
    "def local_peak_locations(data_2d: np.ndarray, neighborhood: np.ndarray, amp_min: float):\n",
    "    \"\"\"\n",
    "    Defines a local neighborhood and finds the local peaks\n",
    "    in the spectrogram, which must be larger than the specified `amp_min`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_2d : numpy.ndarray, shape-(H, W)\n",
    "        The 2D array of data in which local peaks will be detected\n",
    "    \n",
    "    neighborhood : numpy.ndarray, shape-(h, w)\n",
    "        A boolean mask indicating the \"neighborhood\" in which each\n",
    "        datum will be assessed to determine whether or not it is\n",
    "        a local peak. h and w must be odd-valued numbers\n",
    "        \n",
    "    amp_min : float\n",
    "        All amplitudes at and below this value are excluded from being local \n",
    "        peaks.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    List[Tuple[int, int]]\n",
    "        (row, col) index pair for each local peak location, returned\n",
    "        in column-major ordering.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    The local peaks are returned in column-major order, meaning that we \n",
    "    iterate over all nbrhd_row_offsets in a given column of `data_2d` in search for\n",
    "    local peaks, and then move to the next column.\n",
    "    \"\"\"\n",
    "\n",
    "    # We always want our neighborhood to have an odd number\n",
    "    # of nbrhd_row_offsets and nbrhd_col_offsets so that it has a distinct center element\n",
    "    assert neighborhood.shape[0] % 2 == 1\n",
    "    assert neighborhood.shape[1] % 2 == 1\n",
    "    \n",
    "    # Find the indices of the 2D neighborhood where the \n",
    "    # values were `True`\n",
    "    #\n",
    "    # E.g. (row[i], col[i]) stores the row-col index for\n",
    "    # the ith True value in the neighborhood (going in row-major order)\n",
    "    nbrhd_row_indices, nbrhd_col_indices = np.where(neighborhood)\n",
    "    \n",
    "\n",
    "    # Shift the neighbor indices so that the center element resides \n",
    "    # at coordinate (0, 0) and that the center's neighbors are represented\n",
    "    # by \"offsets\" from this center element.\n",
    "    #\n",
    "    # E.g., the neighbor above the center will has the offset (-1, 0), and \n",
    "    # the neighbor to the right of the center will have the offset (0, 1).\n",
    "    nbrhd_row_offsets = nbrhd_row_indices - neighborhood.shape[0] // 2\n",
    "    nbrhd_col_offsets = nbrhd_col_indices - neighborhood.shape[1] // 2\n",
    "\n",
    "    return _peaks(data_2d, nbrhd_row_offsets, nbrhd_col_offsets, amp_min=amp_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcbfa78",
   "metadata": {},
   "source": [
    "Complete the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40252de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_peaks_mask(data: np.ndarray, cutoff: float) -> np.ndarray:\n",
    "    \"\"\"Find local peaks in a 2D array of data and return a 2D array\n",
    "    that is 1 wherever there is a peak and 0 where there is not.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : numpy.ndarray, shape-(H, W)\n",
    "\n",
    "    cutoff : float\n",
    "         A threshold value that distinguishes background from foreground\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Binary indicator, of the same shape as `data`. The value of\n",
    "    1 indicates a local peak.\"\"\"\n",
    "    # Generate a rank-2, connectivity-2 neighborhood array\n",
    "    # We will not use `iterate_structure` in this example\n",
    "    neighborhood_array = generate_binary_structure(2, 2)  # <COGSTUB>\n",
    "\n",
    "    # Use that neighborhood to find the local peaks in `data`.\n",
    "    # Pass `cutoff` as `amp_min` to `local_peak_locations`.\n",
    "    peak_locations = local_peak_locations(data, neighborhood_array, cutoff)  # <COGSTUB>\n",
    "\n",
    "    # Turns the list of (row, col) peak locations into a shape-(N_peak, 2) array\n",
    "    # Save the result to the variable `peak_locations`\n",
    "    peak_locations = np.array(peak_locations)\n",
    "\n",
    "    # create a boolean mask of zeros with the same shape as `data`\n",
    "    mask = np.zeros(data.shape, dtype=bool)\n",
    "\n",
    "    # populate the local peaks with `1`\n",
    "    mask[peak_locations[:, 0], peak_locations[:, 1]] = 1\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2581f4e",
   "metadata": {},
   "source": [
    "Here is a function that will plot the paw prints next to the binary indicator of the local peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b495dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compare(\n",
    "    data: np.ndarray,\n",
    "    peak_rendering_func: Callable[[np.ndarray], np.ndarray],\n",
    "    cutoff: float = -np.inf,\n",
    ") -> Tuple[plt.Figure, plt.Axes]:\n",
    "    \"\"\"Plot the original data side-by-side with the binary indicator\n",
    "    for the local peaks.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : numpy.ndarray, shape=(N, H, W)\n",
    "        N 2D arrays of shape (H, W)\n",
    "\n",
    "    peak_finding_function : Callable[[ndarray], ndarray]\n",
    "        A function that will locate the 2D peaks in `data` and\n",
    "        create an image with the 2D peaks \n",
    "\n",
    "    cutoff : float, optional (default=-np.inf)\n",
    "         A threshold value that distinguishes background from foreground\n",
    "         \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[matplotlib.Figure, matplotlib.Axes]\n",
    "        The figure and axes objects of the plot\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(nrows=len(data), ncols=2)\n",
    "    for i, dat in enumerate(data):\n",
    "        ax[i, 0].imshow(dat)\n",
    "        ax[i, 1].imshow(peak_rendering_func(dat, cutoff=cutoff))\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfe921a",
   "metadata": {},
   "source": [
    "(1.8.5) Now we will plot a comparison of our original data vs the peaks that we identify in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f24b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_compare(paws, local_peaks_mask);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e223aa7",
   "metadata": {},
   "source": [
    "What do you see in these right-column images? \n",
    "Are these precisely the results we are looking for? \n",
    "What seems to be off?\n",
    "\n",
    "Hint: Inspect the paw print data.\n",
    "What value is used to represent the background of the image?\n",
    "What is the default value for `cutoff` in `plot_compare` for distinguishing between foreground and background?\n",
    "\n",
    "> <COGINST>1.8.5 Solution: No, the regions of the image that are blanketed in background (== 0) are also considered to be local peaks, since there are no smaller or larger points in their vicinity.\n",
    "We need to subtract out the background from the image.\n",
    "We can do this by finding `foreground = (data > 0)`, and require that the returned values are local peaks *and* are located in the foreground.</COGINST>\n",
    "\n",
    "\n",
    "Use `plot_compare` again, but this time adjust amplitude cutoff threshold value in order to exclude the background from the peak-finding algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4393710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_compare(paws, local_peaks_mask, cutoff=0.0); # <COGLINE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99e8998",
   "metadata": {},
   "source": [
    "Each paw print should have five distinct peaks -- one for each pad in the puppy's paw. If this is what you see, success! We are now finding local peaks in 2-D data!\n",
    "\n",
    "To summarize this process, we:\n",
    "\n",
    " - Defined a neighborhood that was appropriate for measuring local peaks. This made precise what we mean by \"local\" under specific circumstances.\n",
    " - Demanded that our local peaks be in the \"foreground\" of our data.\n",
    " - Rastered our neighborhood across our 2D data, element-by-element and asked: is the center of this neighborhood the largest value of all the elements in this neighborhood (including tied for largest) and is it larger than our cutoff threshold? If so, then it is a local peak in our 2D data. \n",
    " \n",
    "This will be very useful to help us find the \"fingerprint features\" of a song, given its spectrogram (frequency vs time) data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b51f7f",
   "metadata": {},
   "source": [
    "## Identifying \"Foreground\" vs \"Background\" in Real Data\n",
    "\n",
    "Although this puppy paw print data set is pretty adorable, the fact that the paw print features are neatly embedded in a background of $0$s is too convenient.\n",
    "In reality, we will likely face data where distinguishing background from a salient foreground is subtle (or perhaps entirely ill-posed).\n",
    "\n",
    "Let's consider, for instance, the spectrogram data for the trumpet waveform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f27a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running this cell loads the PCM-encoded data for the trumpet clip\n",
    "import librosa\n",
    "\n",
    "trumpet_audio, sampling_rate = librosa.load(\"data/trumpet.wav\", sr=44100, mono=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b898b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using matplotlib's built-in spectrogram function\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "S, freqs, times, im = ax.specgram(\n",
    "    trumpet_audio,\n",
    "    NFFT=4096,\n",
    "    Fs=sampling_rate,\n",
    "    window=mlab.window_hanning,\n",
    "    noverlap=4096 // 2,\n",
    ")\n",
    "fig.colorbar(im)\n",
    "\n",
    "ax.set_xlabel(\"Time (sec)\")\n",
    "ax.set_ylabel(\"Frequency (Hz)\")\n",
    "ax.set_title(\"Spectrogram of Audio Recording\")\n",
    "ax.set_ylim(0, 6000);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bc2035",
   "metadata": {},
   "source": [
    "To help us identify a \"foreground\" in the log-amplitudes of the spectrogram, we will plot the *cumulative distribution* of the log-amplitudes.\n",
    "This will allow us to identify a useful percentile below which we can consider all amplitudes to be \"background\".\n",
    "\n",
    "The following function can be used to compute [an empirical cumulative distribution function](https://en.wikipedia.org/wiki/Empirical_distribution_function) (ECDF) of our data.\n",
    "The ECDF plots, for some dataset, `percentile(x)` vs `x` -- making it easy to see what proportion of values in our\n",
    "dataset fall below/above any given value `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c71283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ecdf(data):\n",
    "    \"\"\"Returns (x) the sorted data and (y) the empirical cumulative-proportion\n",
    "    of each datum.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : numpy.ndarray, size-N\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[numpy.ndarray shape-(N,), numpy.ndarray shape-(N,)]\n",
    "        Sorted data, empirical CDF values\"\"\"\n",
    "    data = np.asarray(data).ravel()  # flattens the data\n",
    "    y = np.linspace(1 / len(data), 1, len(data))  # stores the cumulative proportion associated with each sorted datum\n",
    "    x = np.sort(data)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386b1b5d",
   "metadata": {},
   "source": [
    "Let's get a feel for what `ecdf` does by using it to plot the cumulative distribution of our log-scaled spectrogram amplitudes.\n",
    "We'll plot this side-by-side with a typical histogram of our log-amplitude values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3a7e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10,5))\n",
    "\n",
    "\n",
    "ax1.hist(np.log(S).ravel(), bins=100, density=True)\n",
    "ax1.set_xlabel(r\"$\\log(|a_{k}|)$\")\n",
    "ax1.set_ylabel(r\"Proportion\")\n",
    "ax1.grid()\n",
    "\n",
    "x, y = ecdf(np.log(S))\n",
    "ax2.plot(x, y)\n",
    "\n",
    "ax2.set_xlabel(r\"$\\log(|a_{k}|)$\")\n",
    "ax2.set_ylabel(r\"Cumulative proportion\")\n",
    "ax2.set_title(\"Cumulative distribution of log-amplitudes\")\n",
    "ax2.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3657fd",
   "metadata": {},
   "source": [
    "This cumulative distribution permits us to look up the percentiles of the log-amplitudes.\n",
    "For example, we can find the log-amplitude below which $80\\%$ of all the other present log-amplitudes fall (roughly $-2.9$).\n",
    "According to the plot above, we see that roughly $90\\%$ of all the log-amplitudes in our spectrogram fall beneath the value $0$.\n",
    "\n",
    "**Consulting the shape of these distributions can help us distinguish a sensible threshold value to distinguish foreground and background**.\n",
    "Here we see an \"elbow\" in the distribution just beyond the $60^\\text{th}$ percentile, near the log-amplitude of $-6.4$, which separates what looks to be a dense Gaussian (or bell-curve) distribution log-amplitudes from a non-Gaussian distribution that seems to peak near $\\log(|a_{k}|)= -6.4$.\n",
    "We might interpret the tall Gaussian distribution to represent background noise, and thus would select our cutoff threshold to eliminate all log-amplitudes below the 60th percentile from our peak-finding process.\n",
    "\n",
    "Suppose we were to decide to use the 60th percentile log-amplitude as the background cutoff threshold for all recordings/spectrograms that we encounter. How can we efficiently identify the 60th-percentile log-amplitude for any given spectrogram, so that we can specify `amp_min` in our `local_peak_locations` function?\n",
    "\n",
    "The simplest way is to sort the amplitude data in ascending order and extract the value at the integer index closest to `len(data) * 0.6`.\n",
    "It is faster, however, for us to use a partitioning technique to find this index value.\n",
    "Read [the documentation](https://numpy.org/doc/stable/reference/generated/numpy.partition.html) for `numpy.partition`, this function will enable us to rapidly find the amplitude associated with the desired percentile without having to sort all of our data.\n",
    "\n",
    "Let's find the log-amplitude associated with the $60\\%$ percentile using `np.partition`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a191a493",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_S = np.log(S).ravel()  # ravel flattens 2D spectrogram into a 1D array\n",
    "ind = round(len(log_S) * 0.6)  # find the index associated with the 60th percentile log-amplitude\n",
    "cutoff_log_amplitude = np.partition(log_S, ind)[ind]  # find the actual 60th percentile log-amplitude\n",
    "cutoff_log_amplitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8882353",
   "metadata": {},
   "source": [
    "We see that $60\\%$ of all the log-amplitudes in the spectrogram fall below $\\log(|a_{k}| = -6.44$.\n",
    "Thus we can use $-6.44$ as a cutoff value for distinguishing foreground from background when finding peaks in the log-amplitude spectrogram for our trumpet audio clip."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python",
   "notebook_metadata_filter": "nbsphinx,-kernelspec"
  },
  "nbsphinx": {
   "execute": "never"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
